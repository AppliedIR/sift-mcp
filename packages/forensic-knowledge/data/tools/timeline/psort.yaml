name: psort
category: timeline
description: "Filter, sort, and export Plaso storage files to various output formats including CSV and dynamic timeline"
platform: [windows, linux, macos]
platform_notes: "Python-based companion to log2timeline/plaso. Works identically on all platforms."
artifacts_parsed: []

caveats:
  - "Requires a Plaso storage file (.plaso) generated by log2timeline as input"
  - "Processing large Plaso storage files can take significant time and memory"
  - "Output format must be specified — common choices are l2tcsv, dynamic, json_line, or xlsx"
  - "Time slice filters use ISO 8601 format and can significantly reduce output volume"
  - "The default output includes all parsed events which can be millions of rows"
  - "Filter expressions use the Plaso filter syntax, not SQL"

output_notes:
  format: csv
  key_fields: [datetime, timestamp_desc, source, sourcetype, type, user, host, filename, message]

exit_code_hints:
  0: "success"
  1: "error"

advisories:
  - "Use -o l2tcsv for log2timeline CSV format compatible with Timeline Explorer and other analysis tools"
  - "Use -o dynamic for human-readable output with configurable fields"
  - "Use --slice to extract events around a specific time: --slice '2024-01-15T10:00:00'"
  - "Use --slice_size to control the time window around the slice (default: 5 minutes)"
  - "Use -w to specify output file path"
  - "Apply time range filters to limit output: --slice '2024-01-15' --slice_size 1440 (full day)"
  - "Workflow: log2timeline.py storage.plaso image → psort.py -o l2tcsv -w timeline.csv storage.plaso"
  - "Use filter expressions to focus on specific data sources or event types"

quick_start: "psort.py -w timeline.csv timeline.plaso"

investigation_sequence:
  - "Export the Plaso storage file to a readable format for analysis"
  - "Use -o l2tcsv for the legacy 17-column format compatible with most timeline tools"
  - "Use -o dynamic for the flexible 8-column default format"
  - "Apply time-based slicing (--slice) to focus on periods of interest while retaining all data"
  - "Use --output-time-zone to convert timestamps to the timezone relevant to the investigation"
  - "Do not use deduplication (default) unless you specifically need to preserve all duplicate entries (-a)"
  - "Review output across all event types — every parser contribution adds context to the timeline"

field_meanings:
  datetime: "ISO 8601 timestamp in dynamic output format"
  timestamp_desc: "Description of what the timestamp represents"
  source: "Short source category"
  source_long: "Detailed source description"
  message: "Event message text"
  parser: "Parser module that extracted the event"
  display_name: "Display-friendly name for the source"
  tag: "Analysis tags applied to the event"
